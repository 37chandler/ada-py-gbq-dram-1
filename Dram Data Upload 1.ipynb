{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25b450e8",
   "metadata": {},
   "source": [
    "## Dram Data Upload\n",
    "\n",
    "<!--\n",
    "Assignment Version: \n",
    "In this assignment, you'll upload Dram shop data to your GBQ account and run a couple of queries against it. The data for this assignment is in a .csv file callled `items-2022-01-01-2022-10-01.csv`. Save this file into the same folder as this repository. This is an example of item-level reports exported from the point-of-sale system at the Dram shop.\n",
    "\n",
    "Your goals are to upload this file to a table in a GBQ data set that you create. Call the table `dram_items_2022`. \n",
    "As always, make sure _not_ to commit any big data files or API keys to your repo.\n",
    "\n",
    "Make your data pipeline idempotent, which means you will be checking for the presence of your tables and, if they exist, deleting them before recreating them. \n",
    "\n",
    "In this assignment you'll use the `pyjanitor` package, which you can install with `pip install pyjanitor`. Then the `import janitor` call will run. This package, which is modeled on the `janitor` package in R, can be used to clean up names in a data frame. If you have a Pandas data frame called `df`, then `df = janitor.clean_names(df)` will give you nice lowercase names with underscores. You can learn more [here](https://github.com/pyjanitor-devs/pyjanitor). \n",
    "--> \n",
    "\n",
    "In this exercise, you'll upload Dram shop data to your GBQ account and run a couple of queries against it. The data for this exercise is in a .csv file callled `items-2022-01-01-2022-10-01.csv`. Save this file into the same folder as this repository. This is an example of item-level reports exported from the point-of-sale system at the Dram shop.\n",
    "\n",
    "Your goals are to upload this file to a table in a GBQ data set that you create. Call the table `dram_items_2022`. \n",
    "As always, make sure _not_ to commit any big data files or API keys to your repo.\n",
    "\n",
    "Make your data pipeline idempotent, which means you will be checking for the presence of your tables and, if they exist, deleting them before recreating them. \n",
    "\n",
    "In this assignment you'll use the `pyjanitor` package, which you can install with `pip install pyjanitor`. Then the `import janitor` call will run. This package, which is modeled on the `janitor` package in R, can be used to clean up names in a data frame. If you have a Pandas data frame called `df`, then `df = janitor.clean_names(df)` will give you nice lowercase names with underscores. You can learn more [here](https://github.com/pyjanitor-devs/pyjanitor). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d503d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_gbq\n",
    "import janitor\n",
    "\n",
    "# Do our imports for the code\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813e659",
   "metadata": {},
   "source": [
    "### GBQ Set Up\n",
    "\n",
    "In this next section we connect to our GBQ project and list the data sets inside to test the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These first two values will be different on your machine. \n",
    "service_path = \"/Users/chandler/Dropbox/Teaching/\"\n",
    "service_file = 'umt-msba-037daf11ee16.json' # change this to your authentication information  \n",
    "gbq_proj_id = 'umt-msba' # change this to your project. \n",
    "\n",
    "# And this should stay the same. \n",
    "private_key =service_path + service_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca232504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we pass in our credentials so that Python has permission to access our project.\n",
    "credentials = service_account.Credentials.from_service_account_file(service_path + service_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally we establish our connection\n",
    "client = bigquery.Client(credentials = credentials, project=gbq_proj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in client.list_datasets() : \n",
    "    print(item.full_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1e74c",
   "metadata": {},
   "source": [
    "### Checking for and deleting monthly tables\n",
    "\n",
    "In this section, check for a table with the name `dram_items_2022`. If that table exists, delete it with the `delete_table` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b9631",
   "metadata": {},
   "source": [
    "### Reading in and modifying data\n",
    "\n",
    "In this section, read in the data using the Pandas `read_csv` function. Once you've read in the data, make the following modifications to it: \n",
    "\n",
    "* Convert the fields that have dollar signs (such as `gross_sales`) into numeric data. Watch out for dollar signs and commas.\n",
    "* Change the type of the column `modifiers_applied` to string.\n",
    "* Replace the `sku` column with a column of empty strings. \n",
    "* Clean the names with the janitor package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a54dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e465a",
   "metadata": {},
   "source": [
    "### Upoad your data to GBQ\n",
    "\n",
    "Using the Pandas function `to_gbq`, upload your data to GBQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff4b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181004b7",
   "metadata": {},
   "source": [
    "### Query your data\n",
    "\n",
    "Let's start by counting the rows in your data. Here's an example of how to do that, though you'll need to update the project and data set parameters in the query below. Note that the query inside the triple quotes can just be run the console. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT COUNT(*)\n",
    "    FROM `umt-msba.dram_shop.dram_items_2022`\n",
    "\"\"\"\n",
    "\n",
    "results = client.query(query)\n",
    "\n",
    "\n",
    "for row in results :\n",
    "    print(f'There were {row[0]} rows.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec28ba",
   "metadata": {},
   "source": [
    "You can also bring results back into a data frame with `pandas_gbq`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8694d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT customer_name, customer_id, SUM(gross_sales) AS gross_sales\n",
    "    FROM `umt-msba.dram_shop.dram_items_2022`\n",
    "    WHERE customer_name != \"\"\n",
    "    GROUP BY customer_name, customer_id\n",
    "    ORDER BY gross_sales DESC\n",
    "\"\"\"\n",
    "\n",
    "customer_spend = pandas_gbq.read_gbq(query,project_id = gbq_proj_id)\n",
    "\n",
    "customer_spend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620774ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_spend.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e497f3",
   "metadata": {},
   "source": [
    "Now some additional work for you. Write a query that returns sales by day by category for the Front Street location to a data frame. Call this data frame `daily_category_sales` with columns `date`, `category`, and `gross_sales` (which is the sum of sales for that date and category.\n",
    "\n",
    "If you've done this correctly, the cells below should run correctly and summarize the data for you and do some plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00eb0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_summary = daily_category_sales.groupby('category').sum('gross_sales').nlargest(10,'gross_sales').reset_index()\n",
    "category_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in category_summary.category : \n",
    "    \n",
    "    df = daily_category_sales.query(f\"category == '{category}'\")\n",
    "    df = df.sort_values('date', ascending=True)\n",
    "    plt.plot(df['date'], df['gross_sales'])\n",
    "    plt.xticks(ticks=range(1,300,30),rotation='vertical')\n",
    "    plt.title(category)\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
